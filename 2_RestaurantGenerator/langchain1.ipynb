{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain crash course\n",
    "\n",
    "## Restaurant idea generator\n",
    "CodeBasics Tutorial: LangChain Crash Course For Beginners | LangChain Tutorial\n",
    "https://www.youtube.com/watch?v=nAmC7SoVLd8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "# models: OpenAI, HuggingFace, etc\n",
    "\n",
    "# temp=0 (most safe) temp=1 (most creative)\n",
    "llm = OpenAI(temperature=0.6)\n",
    "# name = llm(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\")\n",
    "response = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\")\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Mexian. Suggest a fancy name for this.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt template\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine}. Suggest a fancy name for this.\"\n",
    ")\n",
    "prompt_template_name.format(cuisine=\"Mexian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'text': '\\n\\n\"El Dorado Cocina\"'}\n",
      "\n",
      "\n",
      "\"El Dorado Cocina\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "# chain.invoke(\"Italian\")\n",
    "response = chain.invoke(\"Mexican\")\n",
    "text_output = response['text']\n",
    "print(response)\n",
    "print(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential chain\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# chain 1 - Generate restaurant name. \n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine}. Suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "# chain 2 - Generate food menu items based on restaurant name\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"Suggest 5 menu items (only name, no description) for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Chain\n",
    "\n",
    "Gives just one output.   \n",
    "We can get the menu items based on restaurant, but not get the restaurant name output from this chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Mexican', 'output': '\\n\\n1. Enchiladas Supremas\\n2. Chimichangas\\n3. Carne Asada\\n4. Fajitas Trio\\n5. Tres Leches Cake'}\n",
      "\n",
      "\n",
      "1. Enchiladas Supremas\n",
      "2. Chimichangas\n",
      "3. Carne Asada\n",
      "4. Fajitas Trio\n",
      "5. Tres Leches Cake\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
    "response = chain.invoke(\"Mexican\")\n",
    "print(response)\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain\n",
    "\n",
    "Gives multiple outputs.  \n",
    "We can get both the 1) restaurant name and 2) menu items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# chain 1 - Generate restaurant name. \n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine}. Suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name') # added output_key\n",
    "\n",
    "# chain 2 - Generate food menu items based on restaurant name\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template = \"Suggest 5 menu items (only name, no description) for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key='menu_items') # added output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'restaurant_name': '\\n\\n\"Al-Farah Al-Jameel\" (The Beautiful Oasis)', 'menu_items': '\\n\\n1. Lamb Shawarma\\n2. Falafel Platter\\n3. Hummus and Pita Bread\\n4. Chicken Kebab\\n5. Baklava Dessert'}\n"
     ]
    }
   ],
   "source": [
    "chain = SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name', 'menu_items']\n",
    ")\n",
    "response = chain.invoke(\"Arabic\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuisine: Arabic\n",
      "Restaurant Name: \n",
      "\n",
      "\"Al-Farah Al-Jameel\" (The Beautiful Oasis)\n",
      "Menu Items: \n",
      "\n",
      "1. Lamb Shawarma\n",
      "2. Falafel Platter\n",
      "3. Hummus and Pita Bread\n",
      "4. Chicken Kebab\n",
      "5. Baklava Dessert\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cuisine: {response['cuisine']}\")\n",
    "print(f\"Restaurant Name: {response['restaurant_name']}\")\n",
    "print(f\"Menu Items: {response['menu_items']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional topics\n",
    "\n",
    "### Agents\n",
    "\n",
    "Will use agents to call the tools:\n",
    "- SerpAPI - Google Search API\n",
    "- Wikipedia - get information from wikipedia\n",
    "- llm-math - do math operations\n",
    "\n",
    "[List of LangChain Tools available](https://python.langchain.com/docs/integrations/tools/)\n",
    "\n",
    "AgentType: ZERO_SHOT_REACT_DESCRIPTION means agent will have a thought and then reaction to the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\langchain_env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "c:\\ProgramData\\miniconda3\\envs\\langchain_env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birth date\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birth date\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birthdate\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthday\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birthday\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's personal life\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk personal life\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's early life\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk early life\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's education\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk education\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's biography\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk biography\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk birthdate\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's age\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk age\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use Calculator to calculate Elon Musk's age in 2024\n",
      "Action: Calculator\n",
      "Action Input: 2024 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Elon Musk was born on June 28, 1971 and will be 53 years old in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born on June 28, 1971 and will be 53 years old in 2024.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, create_react_agent, load_tools, initialize_agent\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "# run agent with verbose output\n",
    "agent.run(\"When was Elon Musk born? And what is his age today in 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import serpapi_key\n",
    "import os\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This is a math question, so I should use the calculator.\n",
      "Action: Calculator\n",
      "Action Input: 2022 + 5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2027\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the GDP of the US in 2027.\n",
      "Action: Search\n",
      "Action Input: \"US GDP 2027\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m32,274.46\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is the final answer I was looking for.\n",
      "Final Answer: The GDP of the US in 2022 plus 5 is $32,274.46 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GDP of the US in 2022 plus 5 is $32,274.46 billion.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define LLM\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# load tools\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# initialize agent with tools\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "agent.run(\"What was the GDP of US in 2022 plus 5?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"El Sabor de MÃ©xico\"\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "response = chain.invoke(\"Mexican\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our regular chain has no memory of previous interactions.\n",
    "\n",
    "Now we will use `ConversationBufferMemory` to store the conversation history.  \n",
    "This can be used to save/export the conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"El Dorado Cantina\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory) # added memory argument\n",
    "\n",
    "# 1st invocation\n",
    "response = chain.invoke(\"Mexican\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Bella Cucina\"\n"
     ]
    }
   ],
   "source": [
    "# 2nd invocation\n",
    "response = chain.invoke(\"Italian\")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.memory.buffer.ConversationBufferMemory'>\n",
      "chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Mexican'), AIMessage(content='\\n\\n\"El Dorado Cantina\"'), HumanMessage(content='Italian'), AIMessage(content='\\n\\n\"Bella Cucina\"')])\n"
     ]
    }
   ],
   "source": [
    "print(type(chain.memory))\n",
    "print(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "\"El Dorado Cantina\"\n",
      "Human: Italian\n",
      "AI: \n",
      "\n",
      "\"Bella Cucina\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we see the memory of the whole conversation.  \n",
    "\n",
    "Next, we will see the memory enable the model to answer questions based on the previous conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated the Australia team by 17 runs in the final match. The tournament was held in England and was organized by the International Cricket Council. The first match was played between England and India, with England winning by 202 runs.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The sum of 5 and 5 is 10.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the West Indies team during the first cricket world cup was Clive Lloyd. He was known for his strong batting and leadership skills, and he led the team to victory in both the first and second cricket world cups. He was also inducted into the ICC Cricket Hall of Fame in 2003. '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was held in 1975 and was won by the West Indies team. They defeated the Australia team by 17 runs in the final match. The tournament was held in England and was organized by the International Cricket Council. The first match was played between England and India, with England winning by 202 runs.\n",
      "Human: How much is 5+5?\n",
      "AI:  The sum of 5 and 5 is 10.\n",
      "Human: Who was the captain ofthe winning team?\n",
      "AI:  The captain of the West Indies team during the first cricket world cup was Clive Lloyd. He was known for his strong batting and leadership skills, and he led the team to victory in both the first and second cricket world cups. He was also inducted into the ICC Cricket Hall of Fame in 2003. \n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the LLM was able to answer first about the cricket world cup, then a math question, and finally a follow-up question about the cricket world cup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the memory will just keep filling up and fill the context window with conversation history. \n",
    "This large context history might not be neccessary for answering simple questions. It also becomes costly to send soo many tokens through the OpenAI API, which charge per token.\n",
    " \n",
    "Thus, we need to restrict the memory (conversational buffer size) to the last couple of conversational exchanges.   \n",
    "We use `ConversationalBufferWindowMemory` to restrict the memory to the last couple of conversational exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The first cricket world cup was won by the West Indies in 1975. The final match was played between the West Indies and Australia at Lord's Cricket Ground in London. The West Indies won by 17 runs and were led by captain Clive Lloyd. The top scorer for the West Indies was Viv Richards with 138 runs. The first cricket world cup was a 60-over tournament, with each team playing six matches in the group stage. The West Indies had a dominant performance throughout the tournament, winning all six of their matches.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2) # keep last 2 conversations\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The result of 5+5 is 10.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning team was Clive Lloyd. He was a left-handed batsman and a medium-pace bowler for the West Indies team. He also served as the captain for the West Indies team in the 1979 World Cup. Under his leadership, the West Indies team had a record of 36 wins out of 74 matches. He was known for his aggressive and fearless playing style, and he was inducted into the ICC Cricket Hall of Fame in 2004.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seen when using `k=1`, the LLM only remember the last conversational exchange (\"How much is 5+5?\") and don't remember the previous conversation about the cricket world cup.\n",
    "\n",
    "With `k=2` the LLM remembers the last two conversational exchanges and is able to answer the follow-up question about the cricket world cup correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
